{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9af98be",
   "metadata": {},
   "source": [
    "##### Problem Analysis Workshop 4 - 11th November 2025\n",
    "\n",
    "Cemil Caglar Yapici - 9081058"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb27c65",
   "metadata": {},
   "source": [
    "### 1. Convert Factor Variables to Numeric:\n",
    "\n",
    "First, we convert categorical text features (factors) into numeric codes. This is useful for binary or ordinal categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010167f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b59f397",
   "metadata": {},
   "source": [
    "Note: Well There are lots of Datasets (CSV) some of them -our previous workshop's datasets- don't include date so I donwloaded new ones to test here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275022a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Datas/detailed_meals_macros_.csv')\n",
    "\n",
    "# Print dataset dimensions and first few rows\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary categorical 'Gender' to numeric (Male=1, Female=0)\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Convert ordinal categorical 'Activity Level' to numeric codes\n",
    "activity_map = {'Sedentary': 0, 'Lightly Active': 1, 'Moderately Active': 2, 'Very Active': 3}\n",
    "df['Activity Level'] = df['Activity Level'].map(activity_map)\n",
    "\n",
    "# Verify the conversion on the first few records\n",
    "df[['Gender', 'Activity Level']].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7da11",
   "metadata": {},
   "source": [
    "### 2. Convert Calendar Dates to Julian Format:\n",
    "\n",
    "If the dataset contains calendar date fields, we should convert them to a numeric format (Julian date or ordinal) for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Workshop 4 — Calendar → Julian features (ccy)\n",
    "# =========================\n",
    "\n",
    "# 0) Setup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Helper: parse all date-like columns and add Julian features\n",
    "def add_julian_features_ccy(df: pd.DataFrame, cols=None, tz=None, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    - Tries to parse date-like columns to pandas datetime (UTC or given tz).\n",
    "    - Adds:\n",
    "        <col>__datetime       (normalized pandas datetime64[ns, tz])\n",
    "        <col>__ordinal        (Julian day number = datetime.toordinal())\n",
    "        <col>__dayofyear      (Julian day-of-year, 1..366)\n",
    "    - Returns modified DataFrame and a list of processed columns.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Discover candidate columns if not provided\n",
    "    if cols is None:\n",
    "        candidates = []\n",
    "        for c in df.columns:\n",
    "            if re.search(r\"(date|time|timestamp)\", str(c), flags=re.I):\n",
    "                candidates.append(c)\n",
    "        cols = candidates\n",
    "\n",
    "    processed = []\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            continue\n",
    "        # Parse to datetime\n",
    "        dt = pd.to_datetime(\n",
    "            df[c],\n",
    "            errors=\"coerce\",\n",
    "            infer_datetime_format=True,\n",
    "            utc=True if tz is None else False\n",
    "        )\n",
    "        # Localize/convert timezone if requested\n",
    "        if tz is not None:\n",
    "            # If naive, localize; if aware, convert\n",
    "            if dt.dt.tz is None:\n",
    "                dt = dt.dt.tz_localize(tz)\n",
    "            else:\n",
    "                dt = dt.dt.tz_convert(tz)\n",
    "\n",
    "        # Save normalized datetime col\n",
    "        base = f\"{prefix}{c}\"\n",
    "        df[f\"{base}__datetime\"] = dt\n",
    "\n",
    "        # Ordinal (Julian day number) requires naive datetimes -> use .date()\n",
    "        # We'll compute on the UTC/converted wall-clock date\n",
    "        ordinal = df[f\"{base}__datetime\"].dt.tz_convert(\"UTC\") if df[f\"{base}__datetime\"].dt.tz is not None else df[f\"{base}__datetime\"]\n",
    "        ordinal = ordinal.dt.date.map(lambda d: d.toordinal() if pd.notnull(d) else np.nan)\n",
    "        df[f\"{base}__ordinal\"] = ordinal\n",
    "\n",
    "        # Day-of-year (Julian day in year)\n",
    "        df[f\"{base}__dayofyear\"] = df[f\"{base}__datetime\"].dt.dayofyear\n",
    "\n",
    "        processed.append(c)\n",
    "\n",
    "    return df, processed\n",
    "\n",
    "# 2) Load your new datasets\n",
    "path_food = \"Datas/daily_food_nutrition_dataset.csv\"     # uploaded file\n",
    "path_act  = \"Datas/dailyActivity_merged1.csv\"            # uploaded file\n",
    "\n",
    "df_food_ccy = pd.read_csv(path_food)\n",
    "df_act_ccy  = pd.read_csv(path_act)\n",
    "\n",
    "print(\"Shapes -> food:\", df_food_ccy.shape, \"activity:\", df_act_ccy.shape)\n",
    "\n",
    "# 3) Apply the converter\n",
    "#    (Let the helper auto-discover columns: e.g., 'Date', 'ActivityDate', 'Timestamp', etc.)\n",
    "df_food_ccy, food_dates = add_julian_features_ccy(df_food_ccy, cols=None, tz=None, prefix=\"food_\")\n",
    "df_act_ccy, act_dates   = add_julian_features_ccy(df_act_ccy,  cols=None, tz=None, prefix=\"act_\")\n",
    "\n",
    "print(\"Detected date-like columns in food dataset:\", food_dates)\n",
    "print(\"Detected date-like columns in activity dataset:\", act_dates)\n",
    "\n",
    "# 4) Quick sanity check: show new columns created for each dataset\n",
    "def preview_new_date_cols_ccy(df, prefix, n=5):\n",
    "    new_cols = [c for c in df.columns if c.startswith(prefix) and (\"__datetime\" in c or \"__ordinal\" in c or \"__dayofyear\" in c)]\n",
    "    return df[new_cols].head(n)\n",
    "\n",
    "print(\"\\nFOOD — new date features:\")\n",
    "display(preview_new_date_cols_ccy(df_food_ccy, \"food_\"))\n",
    "\n",
    "print(\"\\nACTIVITY — new date features:\")\n",
    "display(preview_new_date_cols_ccy(df_act_ccy, \"act_\"))\n",
    "\n",
    "# 5) (Optional) If you want plain date (yyyy-mm-dd) for merging/EDA:\n",
    "def add_plain_date_ccy(df, datetime_col, out_col=\"PlainDate\"):\n",
    "    df[out_col] = pd.to_datetime(df[datetime_col], errors=\"coerce\").dt.date\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e4e3c",
   "metadata": {},
   "source": [
    "### 3. Convert Categorical Variables to Dummy Variables:\n",
    "\n",
    "For nominal categorical variables with multiple classes (more than two categories), we use dummy encoding (one-hot encoding). This creates new binary indicator columns for each category value:\n",
    "\n",
    "We take Dietary Preference (e.g., Omnivore, Vegetarian, Vegan) and create dummy columns for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03040be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the 'Dietary Preference' nominal category\n",
    "df = pd.get_dummies(df, columns=['Dietary Preference'])\n",
    "\n",
    "# Inspect the new dummy columns alongside original categorical conversions\n",
    "cols_to_show = ['Gender', 'Activity Level'] + [col for col in df.columns if col.startswith('Dietary Preference')]\n",
    "df[cols_to_show].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bce5df",
   "metadata": {},
   "source": [
    "### 4. Apply Box-Cox Transformation:\n",
    "\n",
    "The Box-Cox transformation is a power transformation that can help normalize a skewed distribution of a numeric variable. It finds an optimal exponent (λ) to transform the data closer to a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Box-Cox transformation to the 'Weight' column (must be positive values)\n",
    "weight_data = df['Weight'].dropna()  # ensure no missing values\n",
    "transformed_weight, best_lambda = stats.boxcox(weight_data)\n",
    "\n",
    "# Save the transformed values into a new column\n",
    "df['Weight_BoxCox'] = transformed_weight\n",
    "\n",
    "print(f\"Optimal λ for Box-Cox on Weight: {best_lambda:.4f}\")\n",
    "df[['Weight', 'Weight_BoxCox']].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1accd411",
   "metadata": {},
   "source": [
    "### 5. Apply Tukey’s Ladder of Powers Transformation:\n",
    "\n",
    "Tukey’s Ladder of Powers is another approach to stabilize variance and normalize data by applying various power transformations. It is similar in spirit to Box-Cox but can handle zero or negative values (using, for example, Yeo-Johnson method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ed60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Tukey's Ladder of Powers (via Yeo-Johnson) to 'Snacks Calories'\n",
    "snacks_data = df['Snacks Calories'].fillna(0)  # handle any missing by 0 for demo\n",
    "transformed_snacks, lambda_snacks = stats.yeojohnson(snacks_data)\n",
    "\n",
    "# Save transformed values\n",
    "df['SnacksCalories_Tukey'] = transformed_snacks\n",
    "\n",
    "print(f\"Optimal λ for Tukey (Yeo-Johnson) on Snacks Calories: {lambda_snacks:.4f}\")\n",
    "df[['Snacks Calories', 'SnacksCalories_Tukey']].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df43eb33",
   "metadata": {},
   "source": [
    "### Summary of Transformations\n",
    "\n",
    "\n",
    "This notebook has undergone various data preprocessing procedures with the K-Means project data set. We have numerically converted the categorical features textually based (Gender, Activity Level), further introduced dummy indicator columns for the nominal categories (Dietary Preference). We have converted calendar dates into numerical ordinals for analytical measures (see example date). Via Box-Cox and Tukey's Ladder of Powers, we have conducted transformations of tailored variations of specified numeric data features to decrease skwness and to approximate a normal distribution shape. These steps serve to make the data more amenable to clustering and statistical procedures to follow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
